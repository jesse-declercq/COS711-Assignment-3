{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import KFold \n",
    "from IPython.display import clear_output\n",
    "from scipy.interpolate import interp1d\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from scipy import stats \n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from keras.layers import TimeDistributed,LSTM,Conv1D,Dense,Flatten,ConvLSTM2D,MaxPooling1D, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan(x):\n",
    "    if x==\" \":\n",
    "        return np.nan\n",
    "    else :\n",
    "        return float(x)\n",
    "\n",
    "def norm(x, train_mean, train_std):\n",
    "    return (x - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "features = [\"temp\",\"precip\",\"rel_humidity\",\"wind_dir\",\"wind_spd\",\"atmos_press\"]\n",
    "for feature in features : \n",
    "    train[feature] = train[feature].apply(lambda x: [ replace_nan(X) for X in x.replace(\"nan\",\" \").split(\",\")])\n",
    "    test[feature] = test[feature].apply(lambda x: [ replace_nan(X)  for X in x.replace(\"nan\",\" \").split(\",\")])\n",
    "\n",
    "patterns =  len(train['temp'])\n",
    "entries =  len(train['temp'][0])\n",
    "num_features = len(features)\n",
    "labels = np.array(train['target'])\n",
    "count = 0\n",
    "inputs = [0, 0, 0, 0, 0, 0]\n",
    "for F in features:\n",
    "    with open(F + '.txt', 'r') as f:\n",
    "        l = ([[float(num) for num in line.split(' ')] for line in f])\n",
    "    l = np.array(l)\n",
    "    inputs[count] = l\n",
    "    count += 1\n",
    "    \n",
    "temperature, precipitation, humidity, wind_d, wind_s, pressure = inputs[0], inputs[1], inputs[2], inputs[3], inputs[4], inputs[5]\n",
    "\n",
    "# Locations to numbers\n",
    "for i in range(patterns):\n",
    "    if train['location'][i] == 'A':\n",
    "        train['location'][i] = -1\n",
    "    elif train['location'][i] == 'B':\n",
    "        train['location'][i] = -0.5\n",
    "    elif train['location'][i] == 'C':\n",
    "        train['location'][i] = 0.05\n",
    "    elif train['location'][i] == 'D':\n",
    "        train['location'][i] = 0.5\n",
    "    elif train['location'][i] == 'E':\n",
    "        train['location'][i] = 1\n",
    "\n",
    "        \n",
    "total_features = entries*num_features + 1\n",
    "\n",
    "image = np.zeros((patterns, entries, num_features + 1))\n",
    "vector = np.zeros((patterns, total_features))\n",
    "for i in range(patterns): \n",
    "    image[i,:,0], image[i,:,1],image[i,:,2],image[i,:,3],image[i,:,4], image[i,:,5], image[i,:,6] = temperature[i], precipitation[i], humidity[i], wind_d[i], wind_s[i], pressure[i], np.ones(121)*(train.location[i])\n",
    "#     vector[i,0:121],vector[i,121:242], vector[i,242:363], vector[i,363:484], vector[i,484:605], vector[i,605:726], vector[i,726:] = temperature[i], precipitation[i], humidity[i], wind_d[i], wind_s[i], pressure[i], train['location'][i]\n",
    "clear_output()\n",
    "\n",
    "image_train, image_test, labels_train, labels_test = train_test_split(image, labels, test_size = 0.3, random_state = 777)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model\n",
    "#### Each week is seen as a space in time, and is therfore used as a single feature vector of size 727."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(X, y, epochs, folds, batchsize, sim):\n",
    "    \"---------------------------------------------------------\"\n",
    "    \"This is the LSTM function which takes in a tensor input\"\n",
    "    \"Then returns a fully trained and tested model using the\"\n",
    "    \"k-fold cross validation technique \"\n",
    "    \"---------------------------------------------------------\"\n",
    "    stop = EarlyStopping(monitor='val_loss', patience = 20, mode='min', verbose=0)\n",
    "    training_loss_fold = np.zeros((folds, epochs))\n",
    "    testing_loss_fold = np.zeros((folds, epochs))\n",
    "    \n",
    "    kf = KFold(n_splits = folds, shuffle = True, random_state = 777)\n",
    "    fold = -1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        clear_output()\n",
    "        fold += 1\n",
    "        print(\"Simulation {}\\nFold {}\".format(sim,fold))\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        for i in range(num_features):\n",
    "            m = np.mean(X_train[:,:,i])\n",
    "            s = np.std(X_train[:,:,i])\n",
    "            X_train[:,:,i] = norm(X_train[:,:,i], m, s)\n",
    "            X_test[:,:,i] = norm(X_test[:,:,i], m, s)\n",
    "\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.LSTM(128, dropout = 0.2, \n",
    "                              recurrent_dropout = 0.2, input_shape = (121, 7),\n",
    "                              return_sequences = True))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.Dense(128, activation='relu'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.Dense(1, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer= 'adam', metrics=['mae', 'mse'])\n",
    "        history = model.fit(X_train, y_train, epochs = epochs, batch_size = batchsize, \n",
    "                        validation_data = (X_test, y_test),callbacks=[stop], verbose = 1)\n",
    "        \n",
    "        \n",
    "        loss_train = np.sqrt(history.history['loss'])\n",
    "        loss_test = np.sqrt(history.history['val_loss'])\n",
    "\n",
    "        #Determining Best Model\n",
    "        lowest_test_loss = np.min(loss_test)\n",
    "\n",
    "        if fold == 0:\n",
    "            model_best = model\n",
    "            lowest_validation = lowest_test_loss\n",
    "        elif fold > 0:\n",
    "            if lowest_test_loss < lowest_validation:\n",
    "                model_best = model\n",
    "                lowest_validation = lowest_test_loss\n",
    "\n",
    "        training_loss_fold[fold] = loss_train\n",
    "        testing_loss_fold[fold] = loss_test\n",
    "\n",
    "    return model_best, training_loss_fold, testing_loss_fold, lowest_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 1\n",
      "Fold 1\n",
      "Epoch 1/30\n",
      "43/43 [==============================] - 30s 697ms/step - loss: 5125.9648 - mae: 57.8705 - mse: 5106.2451 - val_loss: 5169.5894 - val_mae: 57.7287 - val_mse: 5157.6743\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 30s 698ms/step - loss: 5008.1738 - mae: 57.2016 - mse: 5026.4141 - val_loss: 5057.9707 - val_mae: 56.7575 - val_mse: 5046.2319\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 30s 695ms/step - loss: 4885.3340 - mae: 56.1161 - mse: 4905.4697 - val_loss: 4915.1592 - val_mae: 55.4902 - val_mse: 4903.6309\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 30s 695ms/step - loss: 4708.3999 - mae: 54.5040 - mse: 4726.8286 - val_loss: 4687.7529 - val_mae: 53.4019 - val_mse: 4676.7905\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 30s 697ms/step - loss: 4483.9551 - mae: 52.3614 - mse: 4498.2661 - val_loss: 4473.9214 - val_mae: 51.3652 - val_mse: 4462.9912\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 30s 697ms/step - loss: 4209.5776 - mae: 49.6965 - mse: 4221.0103 - val_loss: 4169.0518 - val_mae: 48.3566 - val_mse: 4158.5239\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 30s 698ms/step - loss: 3884.4592 - mae: 46.5871 - mse: 3914.6997 - val_loss: 3852.1973 - val_mae: 45.0776 - val_mse: 3842.2214\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 30s 698ms/step - loss: 3571.6750 - mae: 43.1938 - mse: 3592.9939 - val_loss: 3508.3132 - val_mae: 41.3944 - val_mse: 3499.1926\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 30s 700ms/step - loss: 3291.2544 - mae: 39.7448 - mse: 3272.6741 - val_loss: 3217.0566 - val_mae: 38.1649 - val_mse: 3208.4641\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 30s 700ms/step - loss: 2973.5627 - mae: 36.3255 - mse: 2969.2280 - val_loss: 2861.8557 - val_mae: 34.2108 - val_mse: 2853.2695\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 58s 1s/step - loss: 2692.4165 - mae: 33.2397 - mse: 2692.0427 - val_loss: 2638.6963 - val_mae: 31.7281 - val_mse: 2631.3633\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 59s 1s/step - loss: 2490.5564 - mae: 30.6137 - mse: 2453.9736 - val_loss: 2456.9326 - val_mae: 29.8419 - val_mse: 2449.7463\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 62s 1s/step - loss: 2247.4087 - mae: 28.6359 - mse: 2252.2666 - val_loss: 2277.6055 - val_mae: 28.1894 - val_mse: 2270.8677\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 60s 1s/step - loss: 2084.6265 - mae: 27.3552 - mse: 2094.2551 - val_loss: 2117.6787 - val_mae: 27.1581 - val_mse: 2111.8447\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 59s 1s/step - loss: 1972.1405 - mae: 26.7273 - mse: 1978.9601 - val_loss: 2010.0729 - val_mae: 26.7053 - val_mse: 2004.7571\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 60s 1s/step - loss: 1885.0558 - mae: 26.4526 - mse: 1895.7242 - val_loss: 1944.3027 - val_mae: 26.7092 - val_mse: 1939.3301\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 59s 1s/step - loss: 1840.8932 - mae: 26.5734 - mse: 1841.9592 - val_loss: 1889.5610 - val_mae: 27.1737 - val_mse: 1885.6565\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 61s 1s/step - loss: 1834.0710 - mae: 26.7725 - mse: 1808.3542 - val_loss: 1870.3048 - val_mae: 27.2207 - val_mse: 1865.9785\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 60s 1s/step - loss: 1795.7656 - mae: 27.1173 - mse: 1790.0447 - val_loss: 1957.3336 - val_mae: 26.7267 - val_mse: 1952.2571\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 60s 1s/step - loss: 1805.4930 - mae: 27.3703 - mse: 1780.4268 - val_loss: 1889.5577 - val_mae: 27.0345 - val_mse: 1884.8979\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 60s 1s/step - loss: 1773.2075 - mae: 27.6427 - mse: 1773.2883 - val_loss: 1838.9839 - val_mae: 28.0834 - val_mse: 1835.2979\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 38s 886ms/step - loss: 1761.4530 - mae: 27.8154 - mse: 1768.1942 - val_loss: 1834.2809 - val_mae: 28.3791 - val_mse: 1830.9042\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 30s 700ms/step - loss: 1758.2384 - mae: 27.9585 - mse: 1764.8147 - val_loss: 1835.8124 - val_mae: 28.7768 - val_mse: 1832.7004\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 30s 699ms/step - loss: 1751.4025 - mae: 28.0698 - mse: 1763.0883 - val_loss: 1839.6559 - val_mae: 29.2012 - val_mse: 1836.8276\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 30s 702ms/step - loss: 1758.6188 - mae: 28.1063 - mse: 1765.7062 - val_loss: 1829.9863 - val_mae: 28.6408 - val_mse: 1826.5748\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 30s 700ms/step - loss: 1802.9526 - mae: 28.1258 - mse: 1761.7080 - val_loss: 1830.1741 - val_mae: 28.5593 - val_mse: 1826.6946\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 30s 702ms/step - loss: 1752.8813 - mae: 28.2106 - mse: 1761.2593 - val_loss: 1832.0577 - val_mae: 28.5038 - val_mse: 1828.4569\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - ETA: 0s - loss: 1758.6239 - mae: 28.2553 - mse: 1762.4133"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,121,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node sequential_17/lstm_17/transpose_1 (defined at <ipython-input-16-2416c0969f9e>:42) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_test_function_409950]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b99dfa7a5f38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_simulations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmodel_sim_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowest_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Testing model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-2416c0969f9e>\u001b[0m in \u001b[0;36mLSTM\u001b[1;34m(X, y, epochs, folds, batchsize, sim)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mse'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         history = model.fit(X_train, y_train, epochs = epochs, batch_size = batchsize, \n\u001b[1;32m---> 42\u001b[1;33m                         validation_data = (X_test, y_test), verbose = 1)\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    940\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m               return_dict=True)\n\u001b[0m\u001b[0;32m    943\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraceContext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1175\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2405\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2406\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2407\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1653\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1654\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1655\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1730\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1732\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1733\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1734\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,121,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[node sequential_17/lstm_17/transpose_1 (defined at <ipython-input-16-2416c0969f9e>:42) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_test_function_409950]\n\nFunction call stack:\ntest_function\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 5\n",
    "n_simulations = 5\n",
    "epochs = 200\n",
    "batchsize = 128\n",
    "sim_train = np.zeros((n_simulations, epochs))\n",
    "sim_test = np.zeros((n_simulations, epochs))\n",
    "simulation_list = []\n",
    "\n",
    "for sim in range(n_simulations):\n",
    "    model_sim_best, Ltrain, Ltest, lowest_val = LSTM(image_train, labels_train, epochs, k, batchsize, sim)\n",
    "    \n",
    "    # Testing model\n",
    "    m_label = np.mean(image_test)\n",
    "    s_label = np.std(image_test)\n",
    "    X_model = norm(image_test, m_label, s_label)\n",
    "    R = model_sim_best.evaluate(X_model, labels_test, verbose = 0)\n",
    "    simulation_list.append(R[0])\n",
    "    \n",
    "    if sim == 0:\n",
    "        model_best = model_sim_best\n",
    "        val_marker = lowest_val\n",
    "    else:\n",
    "        if lowest_val < val_marker:\n",
    "            model_best = model_sim_best\n",
    "            val_marker = lowest_val\n",
    "    \n",
    "    sim_train[sim] = np.mean(Ltrain, axis = 0)\n",
    "    sim_test[sim] = np.mean(Ltest, axis = 0)\n",
    "    \n",
    "    plt.figure(1)\n",
    "    plt.plot(range(epochs), sim_train[sim], '--', label = 'Simulation {}'.format(sim+1))\n",
    "    plt.figure(2)\n",
    "    plt.plot(range(epochs), sim_test[sim], label = 'Simulation {}'.format(sim+1))\n",
    "\n",
    "    \n",
    "plt.figure(3)    \n",
    "plt.plot(range(epochs), np.mean(sim_train, axis = 0), 'k--')\n",
    "plt.figure(4)    \n",
    "plt.plot(range(epochs), np.mean(sim_test, axis = 0), 'k')\n",
    "\n",
    "clear_output()\n",
    "\n",
    "titles = ['LSTM Simulation Training', 'LSTM Simulation Validation','LSTM Average Training', 'LSTM Average Validation']\n",
    "for i in range(4):\n",
    "    plt.figure(i+1)\n",
    "    plt.title(titles[i])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Root Mean Square Error')\n",
    "    if i == 0 or i == 1:     \n",
    "        plt.legend()   \n",
    "        \n",
    "overfit = np.sqrt(simulation_list) - np.min(sim_train, axis = 1)        \n",
    "train_min_mean = np.mean(np.min(sim_train, axis = 1))\n",
    "train_min_std = np.std(np.min(sim_train, axis = 1))\n",
    "test_min_mean = np.mean(np.min(sim_test, axis = 1))\n",
    "test_min_std = np.std(np.min(sim_test, axis = 1))\n",
    "print('Final Training Mean RMSE:',train_min_mean)\n",
    "print('Final Training STD RMSE:',train_min_std)\n",
    "print('Final Validation Mean RMSE:',test_min_mean)\n",
    "print('Final Validation STD RMSE:',test_min_std)\n",
    "print('The Final Mean RMSE', np.mean(np.sqrt(simulation_list)))\n",
    "print('The Final STD RMSE', np.std(np.sqrt(simulation_list)))\n",
    "print('Overfit Mean', np.mean(overfit))\n",
    "print('Overfit STD', np.std(overfit))\n",
    "#-----------------Saving model------------------\n",
    "# serialize model to JSON\n",
    "model_json = model_best.to_json()\n",
    "with open(\"LSTM_model_best.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_best.save_weights(\"LSTM_model_best.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(model):\n",
    "    epochs_prune = 1\n",
    "    batch = 1000\n",
    "    end_step = np.ceil(1.0 * len(image_train)/batch).astype(np.int32) * epochs_prune\n",
    "    new_pruning_params = {'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity = 0.25,\n",
    "                                                       final_sparsity = 0.25,\n",
    "                                                       begin_step = 0,\n",
    "                                                       end_step = end_step,\n",
    "                                                       frequency = 100)}\n",
    "\n",
    "    new_pruned_model = sparsity.prune_low_magnitude(model, **new_pruning_params)\n",
    "    new_pruned_model.compile(loss = tf.keras.losses.mean_squared_error, optimizer = 'adam', metrics=['mse'])\n",
    "    callbacks = [sparsity.UpdatePruningStep()]\n",
    "    new_pruned_model.fit(image_train, labels_train,\n",
    "              batch_size = batch,\n",
    "              epochs = epochs_prune,\n",
    "              verbose = 1,\n",
    "              callbacks = callbacks)\n",
    "    #           validation_data = (x_val, y_val))\n",
    "\n",
    "    clear_output()\n",
    "    final_model = sparsity.strip_pruning(new_pruned_model)\n",
    "    score = new_pruned_model.evaluate(image_test, labels_test, verbose = 0)\n",
    "    print('initial test RMSE = {:.2f}'.format(np.mean(np.sqrt(simulation_list))))\n",
    "    print('The final test RMSE on the model is {:.2f}'.format(np.sqrt(score[0])))\n",
    "    \n",
    "    return new_pruned_model\n",
    "\n",
    "prune(model_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
